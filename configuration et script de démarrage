# config.py
"""
Configuration du syst√®me de candidature automatique
"""

import os
from pathlib import Path

# =============================================================================
# CONFIGURATION G√âN√âRALE
# =============================================================================

# R√©pertoire de travail
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
LOGS_DIR = BASE_DIR / "logs"
CV_DIR = BASE_DIR / "cv_templates"

# Cr√©ation des dossiers s'ils n'existent pas
for directory in [DATA_DIR, LOGS_DIR, CV_DIR]:
    directory.mkdir(exist_ok=True)

# =============================================================================
# CONFIGURATION API
# =============================================================================

# OpenAI (obligatoire pour l'adaptation du CV)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
if not OPENAI_API_KEY:
    print("‚ö†Ô∏è  ATTENTION: Cl√© OpenAI manquante. D√©finissez OPENAI_API_KEY dans vos variables d'environnement")

# =============================================================================
# CONFIGURATION RECHERCHE D'EMPLOI
# =============================================================================

# Profil de recherche de Juliana
SEARCH_PROFILES = {
    "data_scientist": {
        "keywords": "data scientist python machine learning",
        "location": "√éle-de-France",
        "exclude_keywords": ["stage", "intern", "b√©n√©vole", "freelance"],
        "min_salary": 40000,  # Salaire minimum attendu
        "max_pages_per_site": 5
    },
    
    "scrum_master": {
        "keywords": "scrum master agile project manager",
        "location": "√éle-de-France", 
        "exclude_keywords": ["stage", "intern", "b√©n√©vole"],
        "min_salary": 45000,
        "max_pages_per_site": 3
    },
    
    "data_analyst": {
        "keywords": "data analyst business intelligence power bi",
        "location": "√éle-de-France",
        "exclude_keywords": ["stage", "intern", "b√©n√©vole"],
        "min_salary": 35000,
        "max_pages_per_site": 4
    }
}

# Profil par d√©faut
DEFAULT_PROFILE = "data_scientist"

# =============================================================================
# CONFIGURATION SITES DE RECHERCHE
# =============================================================================

SITES_CONFIG = {
    "indeed": {
        "enabled": True,
        "base_url": "https://fr.indeed.com/jobs",
        "priority": 1,  # Plus prioritaire
        "delay_between_requests": (2, 5),  # secondes (min, max)
    },
    
    "linkedin": {
        "enabled": False,  # N√©cessite une connexion
        "base_url": "https://www.linkedin.com/jobs/search/",
        "priority": 2,
        "delay_between_requests": (3, 7),
    },
    
    "welcome_to_the_jungle": {
        "enabled": True,
        "base_url": "https://www.welcometothejungle.com/fr/jobs",
        "priority": 3,
        "delay_between_requests": (2, 4),
    }
}

# =============================================================================
# CONFIGURATION CANDIDATURE
# =============================================================================

APPLICATION_CONFIG = {
    # D√©lais pour √©viter la d√©tection
    "delay_between_applications": {
        "min": 30,  # secondes
        "max": 120,
        "variation": 0.2  # Variation al√©atoire ¬±20%
    },
    
    # Limites journali√®res
    "daily_limits": {
        "max_applications_per_day": 50,
        "max_applications_per_hour": 10,
        "pause_after_applications": 5,  # Pause apr√®s X candidatures
        "pause_duration": 300  # Dur√©e de pause en secondes
    },
    
    # Filtres qualit√©
    "quality_filters": {
        "min_description_length": 200,  # Caract√®res minimum dans la description
        "exclude_companies": [],  # Entreprises √† √©viter
        "require_salary": False,  # Exiger que le salaire soit mentionn√©
        "max_application_age_days": 7  # Ne pas postuler aux offres de plus de 7 jours
    }
}

# =============================================================================
# CONFIGURATION CV
# =============================================================================

CV_CONFIG = {
    # Template de base (sera adapt√© pour chaque offre)
    "base_template_path": CV_DIR / "juliana_base_cv.txt",
    
    # Sections adaptables
    "adaptable_sections": {
        "title": True,  # Titre du poste recherch√©
        "skills": True,  # Ordre et emphase des comp√©tences
        "experience_descriptions": True,  # Reformulation des exp√©riences
        "keywords_integration": True  # Int√©gration naturelle des mots-cl√©s
    },
    
    # R√®gles d'adaptation
    "adaptation_rules": {
        "keep_structure": True,  # Garder la structure originale
        "max_keywords_per_section": 5,  # Max mots-cl√©s √† int√©grer par section
        "synonym_replacement": True,  # Remplacer par des synonymes
        "preserve_achievements": True  # Garder les chiffres et r√©sultats
    }
}

# =============================================================================
# CONFIGURATION BASE DE DONN√âES
# =============================================================================

DATABASE_CONFIG = {
    "path": DATA_DIR / "jobs.db",
    "backup_frequency": "daily",  # daily, weekly
    "cleanup_old_jobs_days": 90,  # Supprimer les jobs de plus de 90 jours
    "export_formats": ["csv", "excel"]  # Formats d'export disponibles
}

# =============================================================================
# CONFIGURATION LOGS
# =============================================================================

LOGGING_CONFIG = {
    "level": "INFO",  # DEBUG, INFO, WARNING, ERROR
    "file_path": LOGS_DIR / "job_automation.log",
    "max_file_size_mb": 10,
    "backup_count": 5,
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
}

# =============================================================================
# CONFIGURATION SELENIUM
# =============================================================================

SELENIUM_CONFIG = {
    "headless": True,  # Mode sans interface graphique
    "window_size": (1920, 1080),
    "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "implicit_wait": 10,  # Attente implicite en secondes
    "page_load_timeout": 30,  # Timeout de chargement de page
    "download_dir": DATA_DIR / "downloads"
}

# =============================================================================
# FONCTIONS UTILITAIRES
# =============================================================================

def get_profile_config(profile_name: str = None) -> dict:
    """R√©cup√®re la configuration d'un profil de recherche"""
    if profile_name is None:
        profile_name = DEFAULT_PROFILE
    
    return SEARCH_PROFILES.get(profile_name, SEARCH_PROFILES[DEFAULT_PROFILE])

def validate_config() -> bool:
    """Valide la configuration"""
    errors = []
    
    # V√©rification des cl√©s API
    if not OPENAI_API_KEY:
        errors.append("Cl√© OpenAI manquante")
    
    # V√©rification des fichiers requis
    if not CV_CONFIG["base_template_path"].exists():
        errors.append(f"Template CV manquant: {CV_CONFIG['base_template_path']}")
    
    # V√©rification des profils
    if not SEARCH_PROFILES:
        errors.append("Aucun profil de recherche d√©fini")
    
    if errors:
        print("‚ùå Erreurs de configuration:")
        for error in errors:
            print(f"  - {error}")
        return False
    
    print("‚úÖ Configuration valide")
    return True

# startup.py
"""
Script de d√©marrage du syst√®me de candidature automatique
"""

import sys
import argparse
from pathlib import Path
import logging
from config import *
from job_automation_system import JobAutomationSystem
import subprocess

def setup_logging():
    """Configure le syst√®me de logging"""
    logging.basicConfig(
        level=getattr(logging, LOGGING_CONFIG["level"]),
        format=LOGGING_CONFIG["format"],
        handlers=[
            logging.FileHandler(LOGGING_CONFIG["file_path"]),
            logging.StreamHandler(sys.stdout)
        ]
    )

def create_cv_template():
    """Cr√©e le template de CV s'il n'existe pas"""
    cv_path = CV_CONFIG["base_template_path"]
    
    if not cv_path.exists():
        print(f"üìù Cr√©ation du template CV: {cv_path}")
        
        cv_content = """JULIANA NIAPOH
CDI DATA & IA | SCRUM MASTER & GESTION DE PROJET AGILE

CONTACT
üìç 93300, Aubervilliers | üïí Disponibilit√© : Octobre 2025
üìß Jniapoh@gmail.com | üìû 0622855341
üîó LinkedIn | Portfolio/website

EXP√âRIENCES PROFESSIONNELLES

Alternance Assistante cheffe de projet num√©rique (2024/2025)
SNCF, Saint-Denis - FERROVIAIRE
‚Ä¢ Coordination de projets IT en mode Agile (Scrum), pilotage de projets de transformation num√©rique
‚Ä¢ Gestion d'un portail collaboratif pour la m√©decine du travail, r√©duisant les d√©lais de communication de 30%
‚Ä¢ Support utilisateur niveau 3 et r√©solution d'incidents complexes
‚Ä¢ Animation de formations techniques et fonctionnelles pour les nouveaux outils d√©ploy√©s

Alternance Charg√©e de projet Digital (2022/2023)
ORANO, Ch√¢tillon - √âNERGIE NUCL√âAIRE
‚Ä¢ Analyse et optimisation des flux de donn√©es existants
‚Ä¢ D√©veloppement de solutions de donn√©es et coordination des √©quipes
‚Ä¢ Formation des √©quipes √† l'utilisation des nouveaux outils de visualisation
‚Ä¢ Cr√©ation de guides et documentation utilisateur

FORMATION
Master Data Management (2023/2025) - Paris School of Business, Paris
Bachelor E-commerce & Marketing num√©rique (2022/2023) - Paris School of Business, Paris
DUT Statistiques & Informatiques D√©cisionnelles (2020/2022) - Universit√© Sorbonne Paris Nord

COMP√âTENCES TECHNIQUES
‚Ä¢ Langages: Python, SQL, R, JavaScript, HTML/CSS
‚Ä¢ Machine Learning: Scikit-learn, algorithmes pr√©dictifs, NLP
‚Ä¢ Data Visualisation: Power BI, Tableau de bord, Jupyter Notebook
‚Ä¢ Big Data: Analyse de grands ensembles de donn√©es, nettoyage de donn√©es
‚Ä¢ Gestion de Projet: M√©thode Agile (Scrum, Kanban), Jira, Trello
‚Ä¢ Bases de Donn√©es: Requ√™tes complexes, optimisation, migration

PROJETS ACAD√âMIQUES
‚Ä¢ Base de donn√©es SQL WorkBench: Conception et optimisation d'une base de donn√©es relationnelle
‚Ä¢ IA Student Assistance: D√©veloppement d'une solution d'assistance √©tudiante bas√©e sur l'IA (NLP)
‚Ä¢ Tableau de bord RH (Python): Outil de visualisation des donn√©es RH avec Python (Pandas, Matplotlib, Streamlit)

SOFT SKILLS
‚Ä¢ Esprit d'analyse et r√©solution de probl√®mes complexes
‚Ä¢ Collaboration en √©quipe et coordination
‚Ä¢ Adaptabilit√© et gestion du changement
‚Ä¢ Communication et formation d'√©quipes"""
        
        with open(cv_path, 'w', encoding='utf-8') as f:
            f.write(cv_content)
        
        print("‚úÖ Template CV cr√©√© avec succ√®s")

def run_dashboard():
    """Lance le dashboard web"""
    print("üöÄ Lancement du dashboard web...")
    try:
        subprocess.run([sys.executable, "-m", "streamlit", "run", "dashboard.py"], check=True)
    except subprocess.CalledProcessError:
        print("‚ùå Erreur lors du lancement du dashboard")
        print("Installez streamlit: pip install streamlit")

def run_automation(profile: str, dry_run: bool = False):
    """Lance l'automatisation"""
    print(f"ü§ñ D√©marrage de l'automatisation avec le profil: {profile}")
    
    if not validate_config():
        return False
    
    profile_config = get_profile_config(profile)
    
    if dry_run:
        print("üß™ Mode DRY RUN - Aucune candidature ne sera envoy√©e")
        print(f"Configuration utilis√©e: {profile_config}")
        return True
    
    try:
        system = JobAutomationSystem(OPENAI_API_KEY)
        system.run_full_cycle(
            search_keywords=profile_config["keywords"],
            location=profile_config["location"]
        )
        
        # Affichage des r√©sultats
        dashboard_data = system.get_dashboard_data()
        print("\nüìä R√âSULTATS:")
        print(f"Total offres scrap√©es: {dashboard_data['total_jobs']}")
        print(f"Candidatures envoy√©es: {dashboard_data['applied']}")
        print(f"R√©ponses re√ßues: {dashboard_data['responded']}")
        
        return True
        
    except Exception as e:
        logging.error(f"Erreur lors de l'automatisation: {e}")
        return False
    finally:
        if 'system' in locals():
            system.cleanup()

def main():
    """Point d'entr√©e principal"""
    parser = argparse.ArgumentParser(description="Syst√®me de candidature automatique")
    
    parser.add_argument("command", choices=["dashboard", "run", "setup", "validate"], 
                       help="Commande √† ex√©cuter")
    
    parser.add_argument("--profile", default=DEFAULT_PROFILE,
                       choices=list(SEARCH_PROFILES.keys()),
                       help="Profil de recherche √† utiliser")
    
    parser.add_argument("--dry-run", action="store_true",
                       help="Mode test sans envoi de candidatures")
    
    args = parser.parse_args()
    
    # Configuration du logging
    setup_logging()
    
    print("ü§ñ Syst√®me de Candidature Automatique - Juliana Niapoh")
    print("=" * 60)
    
    if args.command == "setup":
        print("‚öôÔ∏è  Configuration initiale...")
        create_cv_template()
        validate_config()
        print("\n‚úÖ Configuration termin√©e!")
        print("\nCommandes disponibles:")
        print("  - python startup.py dashboard  # Lance l'interface web")
        print("  - python startup.py run        # Lance l'automatisation")
        print("  - python startup.py validate   # Valide la configuration")
    
    elif args.command == "validate":
        validate_config()
    
    elif args.command == "dashboard":
        run_dashboard()
    
    elif args.command == "run":
        success = run_automation(args.profile, args.dry_run)
        if not success:
            sys.exit(1)
    
    print("\nüéâ Termin√©!")

if __name__ == "__main__":
    main()

# requirements.txt
"""
D√©pendances Python n√©cessaires
"""

# Web scraping
selenium==4.15.2
beautifulsoup4==4.12.2
requests==2.31.0

# Data processing
pandas==2.1.3
numpy==1.24.3

# AI/ML
openai==0.28.1
scikit-learn==1.3.2

# Database
sqlite3  # Inclus dans Python

# Dashboard
streamlit==1.28.1
plotly==5.17.0

# Utilities
python-dotenv==1.0.0
pathlib  # Inclus dans Python

# Development
pytest==7.4.3
black==23.11.0

# install.bat (pour Windows)
@echo off
echo Installation du systeme de candidature automatique
echo ==================================================

echo Installation des dependances Python...
pip install -r requirements.txt

echo Verification de Chrome et ChromeDriver...
echo ATTENTION: Vous devez installer ChromeDriver manuellement
echo Telechargez-le sur: https://chromedriver.chromium.org/
echo Et placez-le dans votre PATH

echo Configuration initiale...
python startup.py setup

echo Installation terminee!
echo Lancez le dashboard avec: python startup.py dashboard
pause

# install.sh (pour Linux/Mac)
#!/bin/bash
echo "Installation du syst√®me de candidature automatique"
echo "=================================================="

echo "Installation des d√©pendances Python..."
pip install -r requirements.txt

echo "V√©rification de Chrome et ChromeDriver..."
if ! command -v google-chrome &> /dev/null; then
    echo "ATTENTION: Google Chrome n'est pas install√©"
fi

if ! command -v chromedriver &> /dev/null; then
    echo "ATTENTION: ChromeDriver n'est pas install√©"
    echo "Installez-le avec: sudo apt-get install chromium-chromedriver"
fi

echo "Configuration initiale..."
python startup.py setup

echo "Installation termin√©e!"
echo "Lancez le dashboard avec: python startup.py dashboard"
